{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-size:1.5em;\"> Creating Trim Datasets\n",
    "Author: Angela Kim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T20:10:36.917038Z",
     "start_time": "2022-01-20T20:10:35.990964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I trim down the merged datasets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T20:14:27.095920Z",
     "start_time": "2022-01-20T20:10:36.922066Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# Import all datasets\n",
    "O3original = pd.read_csv('O3.csv')\n",
    "COoriginal = pd.read_csv('CO.csv')\n",
    "NO2original = pd.read_csv('NO2.csv')\n",
    "SO2original = pd.read_csv('SO2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T20:14:27.158788Z",
     "start_time": "2022-01-20T20:14:27.121109Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to trim all four datasets\n",
    "\n",
    "def trim_dataset(df, pollutant):\n",
    "    \"\"\"\n",
    "    Trims down pollution datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "    pollutant: str, name of pollutant\n",
    "    \n",
    "    Returns:\n",
    "    ----------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # Drop columns that are not US states or DC\n",
    "    df.drop(df[(df['State Name'] == 'Country Of Mexico') | \n",
    "               (df['State Name'] == 'Virgin Islands') | \n",
    "               (df['State Name'] == 'Canada') | \n",
    "               (df['State Name'] == 'Puerto Rico')].index, inplace=True)\n",
    "    \n",
    "    # Drop pollutant standards that do not produce AQI values\n",
    "    if pollutant == 'CO':\n",
    "        df.drop(df[df['Pollutant Standard'] == ('CO 1-hour 1971')].index, inplace=True)\n",
    "    elif pollutant == 'SO2':\n",
    "        df.drop(df[df['Pollutant Standard'] == ('SO2 3-hour 1971')].index, inplace=True)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # Drop columns that are redundant or unnecessary\n",
    "    df.drop(['State Code', 'County Code', 'Site Num', 'Parameter Code', 'POC', 'Latitude', 'Longitude', \n",
    "             'Datum', 'Parameter Name', 'Sample Duration', 'Pollutant Standard', 'Units of Measure', \n",
    "             'Event Type', 'Observation Count', 'Observation Percent', 'Method Code', 'Method Name', \n",
    "             'Local Site Name', 'Address', 'CBSA Name', 'Date of Last Change'], axis=1, inplace=True)\n",
    "    \n",
    "    # Convert dates to datetime format\n",
    "    df['Date Local'] = pd.to_datetime(df['Date Local'])\n",
    "    \n",
    "    # Reorder columns for neatness\n",
    "    reordered = ['Date Local', 'State Name', 'County Name', 'City Name', \n",
    "                 'Arithmetic Mean', '1st Max Value', '1st Max Hour', 'AQI']\n",
    "    \n",
    "    df = df.reindex(columns=reordered)\n",
    "    \n",
    "    # Rename columns for neatness\n",
    "    df = df.rename(columns={'Date Local': 'Date', \n",
    "                            'Arithmetic Mean': 'Mean', \n",
    "                            'AQI': '{} AQI'.format(pollutant), \n",
    "                            'State Name': 'State', \n",
    "                            'County Name': 'County', \n",
    "                            'City Name': 'City'})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T20:15:36.507042Z",
     "start_time": "2022-01-20T20:14:27.163452Z"
    }
   },
   "outputs": [],
   "source": [
    "# Applying the function to datasets\n",
    "O3 = trim_dataset(O3original, 'O3')\n",
    "CO = trim_dataset(COoriginal, 'CO')\n",
    "NO2 = trim_dataset(NO2original, 'NO2')\n",
    "SO2 = trim_dataset(SO2original, 'SO2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T20:20:39.875196Z",
     "start_time": "2022-01-20T20:15:36.520334Z"
    }
   },
   "outputs": [],
   "source": [
    "# Export as csv\n",
    "# O3.to_csv('O3trim.csv', index=False)\n",
    "# CO.to_csv('COtrim.csv', index=False)\n",
    "# NO2.to_csv('NO2trim.csv', index=False)\n",
    "# SO2.to_csv('SO2trim.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pollution All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T20:20:39.924183Z",
     "start_time": "2022-01-20T20:20:39.917281Z"
    }
   },
   "outputs": [],
   "source": [
    "# O3df = O3.copy()\n",
    "# COdf = CO.copy()\n",
    "# SO2df = SO2.copy()\n",
    "# NO2df = NO2.copy()\n",
    "\n",
    "# df1 = pd.merge(O3df, COdf, how='inner', \n",
    "#                left_on=['Date', 'Address', 'State', 'County', 'City'], \n",
    "#                right_on=['Date', 'Address', 'State', 'County', 'City'])\n",
    "# df2 = pd.merge(df1, SO2df, how='inner', \n",
    "#                left_on=['Date', 'Address', 'State', 'County', 'City'], \n",
    "#                right_on=['Date', 'Address', 'State', 'County', 'City'])\n",
    "# df3 = pd.merge(df2, NO2df, how='inner', \n",
    "#                left_on=['Date', 'Address', 'State', 'County', 'City'], \n",
    "#                right_on=['Date', 'Address', 'State', 'County', 'City'])\n",
    "# df_final = df3.copy()\n",
    "# df_final['Date'] = pd.to_datetime(df_final['Date'])\n",
    "# df_final['Day'] = df_final['Date'].dt.day\n",
    "# df_final['Month'] = df_final['Date'].dt.month\n",
    "# df_final['Year'] = df_final['Date'].dt.year\n",
    "# reordered = ['Date', 'Year', 'Month', 'Day', 'Address', 'State', 'County', 'City', \n",
    "#              'O3 Mean', 'O3 1st Max Value', 'O3 1st Max Hour', 'O3 AQI', \n",
    "#              'CO Mean', 'CO 1st Max Value', 'CO 1st Max Hour', 'CO AQI', \n",
    "#              'SO2 Mean', 'SO2 1st Max Value', 'SO2 1st Max Hour', 'SO2 AQI', \n",
    "#              'NO2 Mean', 'NO2 1st Max Value', 'NO2 1st Max Hour', 'NO2 AQI']\n",
    "# df_final = df_final.reindex(columns=reordered)\n",
    "# df_final.to_csv('pollution_2000_2021.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
