{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-size:1.5em;\"> Forecasting Air Quality in New York City\n",
    "Author: Angela Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-size:1.2em;\"> Contents\n",
    "<l></l>\n",
    "\n",
    "<span style=\"font-size:1.2em;\">\n",
    "\n",
    "- <a href=\"#Overview\">Overview</a>\n",
    "    \n",
    "- <a href=\"#Imports\">Imports</a>\n",
    "    \n",
    "    - <a href=\"#Ozone\">Ozone</a>\n",
    "    \n",
    "    - <a href=\"#Carbon Monoxide\">Carbon Monoxide</a>\n",
    "    \n",
    "    - <a href=\"#Nitrogen Dioxide\">Nitrogen Dioxide</a>\n",
    "\n",
    "    - <a href=\"#Sulfur Dioxide\">Sulfur Dioxide</a>\n",
    "    \n",
    "- <a href=\"#Creating Trim Pollutant Datasets\">Creating Trim Pollutant Datasets</a>\n",
    "\n",
    "- <a href=\"#Creating Time Series Datasets\">Creating Time Series Datasets</a>\n",
    "    \n",
    "- <a href=\"#Export\">Export</a>\n",
    "\n",
    "- <a href=\"#Sources\">Sources</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-size:1.2em;\"> <a id=\"Overview\">Overview</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-size:1.2em;\"> <a id=\"Imports\">Imports</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T22:26:53.387397Z",
     "start_time": "2022-01-26T22:26:50.223254Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from statsmodels.tsa.arima_model import ARMA, ARIMA, ARIMAResults\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T22:26:53.606417Z",
     "start_time": "2022-01-26T22:26:53.393270Z"
    }
   },
   "outputs": [],
   "source": [
    "O3 = pd.read_csv('data/nycO3.csv')\n",
    "CO = pd.read_csv('data/nycCO.csv')\n",
    "NO2 = pd.read_csv('data/nycNO2.csv')\n",
    "SO2 = pd.read_csv('data/nycSO2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-size:1.2em;\"> <a id=\"Ozone\">Ozone</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T15:18:32.652808Z",
     "start_time": "2022-01-25T15:17:51.836559Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Ozone datasets\n",
    "O3_2000 = pd.read_csv('data/dailyO3/daily_44201_2000.csv')\n",
    "O3_2001 = pd.read_csv('data/dailyO3/daily_44201_2001.csv')\n",
    "O3_2002 = pd.read_csv('data/dailyO3/daily_44201_2002.csv')\n",
    "O3_2003 = pd.read_csv('data/dailyO3/daily_44201_2003.csv')\n",
    "O3_2004 = pd.read_csv('data/dailyO3/daily_44201_2004.csv')\n",
    "O3_2005 = pd.read_csv('data/dailyO3/daily_44201_2005.csv')\n",
    "O3_2006 = pd.read_csv('data/dailyO3/daily_44201_2006.csv')\n",
    "O3_2007 = pd.read_csv('data/dailyO3/daily_44201_2007.csv')\n",
    "O3_2008 = pd.read_csv('data/dailyO3/daily_44201_2008.csv')\n",
    "O3_2009 = pd.read_csv('data/dailyO3/daily_44201_2009.csv')\n",
    "O3_2010 = pd.read_csv('data/dailyO3/daily_44201_2010.csv')\n",
    "O3_2011 = pd.read_csv('data/dailyO3/daily_44201_2011.csv')\n",
    "O3_2012 = pd.read_csv('data/dailyO3/daily_44201_2012.csv')\n",
    "O3_2013 = pd.read_csv('data/dailyO3/daily_44201_2013.csv')\n",
    "O3_2014 = pd.read_csv('data/dailyO3/daily_44201_2014.csv')\n",
    "O3_2015 = pd.read_csv('data/dailyO3/daily_44201_2015.csv')\n",
    "O3_2016 = pd.read_csv('data/dailyO3/daily_44201_2016.csv')\n",
    "O3_2017 = pd.read_csv('data/dailyO3/daily_44201_2017.csv')\n",
    "O3_2018 = pd.read_csv('data/dailyO3/daily_44201_2018.csv')\n",
    "O3_2019 = pd.read_csv('data/dailyO3/daily_44201_2019.csv')\n",
    "O3_2020 = pd.read_csv('data/dailyO3/daily_44201_2020.csv')\n",
    "O3_2021 = pd.read_csv('data/dailyO3/daily_44201_2021.csv')\n",
    "\n",
    "\n",
    "# Concatenate datasets\n",
    "O3_all = [O3_2000, O3_2001, O3_2002, O3_2003, O3_2004, O3_2005, O3_2006, O3_2007, O3_2008, O3_2009, O3_2010, \n",
    "          O3_2011, O3_2012, O3_2013, O3_2014, O3_2015, O3_2016, O3_2017, O3_2018, O3_2019, O3_2020, O3_2021]\n",
    "\n",
    "O3 = pd.concat(O3_all, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T22:12:43.711053Z",
     "start_time": "2022-01-18T22:10:24.802435Z"
    }
   },
   "source": [
    "## <span style=\"font-size:1.2em;\"> <a id=\"Carbon Monoxide\">Carbon Monoxide</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T15:19:02.957001Z",
     "start_time": "2022-01-25T15:18:32.659163Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Carbon Monoxide datasets\n",
    "CO_2000 = pd.read_csv('data/dailyCO/daily_42101_2000.csv')\n",
    "CO_2001 = pd.read_csv('data/dailyCO/daily_42101_2001.csv')\n",
    "CO_2002 = pd.read_csv('data/dailyCO/daily_42101_2002.csv')\n",
    "CO_2003 = pd.read_csv('data/dailyCO/daily_42101_2003.csv')\n",
    "CO_2004 = pd.read_csv('data/dailyCO/daily_42101_2004.csv')\n",
    "CO_2005 = pd.read_csv('data/dailyCO/daily_42101_2005.csv')\n",
    "CO_2006 = pd.read_csv('data/dailyCO/daily_42101_2006.csv')\n",
    "CO_2007 = pd.read_csv('data/dailyCO/daily_42101_2007.csv')\n",
    "CO_2008 = pd.read_csv('data/dailyCO/daily_42101_2008.csv')\n",
    "CO_2009 = pd.read_csv('data/dailyCO/daily_42101_2009.csv')\n",
    "CO_2010 = pd.read_csv('data/dailyCO/daily_42101_2010.csv')\n",
    "CO_2011 = pd.read_csv('data/dailyCO/daily_42101_2011.csv')\n",
    "CO_2012 = pd.read_csv('data/dailyCO/daily_42101_2012.csv')\n",
    "CO_2013 = pd.read_csv('data/dailyCO/daily_42101_2013.csv')\n",
    "CO_2014 = pd.read_csv('data/dailyCO/daily_42101_2014.csv')\n",
    "CO_2015 = pd.read_csv('data/dailyCO/daily_42101_2015.csv')\n",
    "CO_2016 = pd.read_csv('data/dailyCO/daily_42101_2016.csv')\n",
    "CO_2017 = pd.read_csv('data/dailyCO/daily_42101_2017.csv')\n",
    "CO_2018 = pd.read_csv('data/dailyCO/daily_42101_2018.csv')\n",
    "CO_2019 = pd.read_csv('data/dailyCO/daily_42101_2019.csv')\n",
    "CO_2020 = pd.read_csv('data/dailyCO/daily_42101_2020.csv')\n",
    "CO_2021 = pd.read_csv('data/dailyCO/daily_42101_2021.csv')\n",
    "\n",
    "\n",
    "# Concatenate datasets\n",
    "CO_all = [CO_2000, CO_2001, CO_2002, CO_2003, CO_2004, CO_2005, CO_2006, CO_2007, CO_2008, CO_2009, CO_2010,\n",
    "          CO_2011, CO_2012, CO_2013, CO_2014, CO_2015, CO_2016, CO_2017, CO_2018, CO_2019, CO_2020, CO_2021]\n",
    "\n",
    "CO = pd.concat(CO_all, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-size:1.2em;\"> <a id=\"Nitrogen Dioxide\">Nitrogen Dioxide</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T15:19:20.760029Z",
     "start_time": "2022-01-25T15:19:02.975686Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Nitrogen Dioxide datasets\n",
    "NO2_2000 = pd.read_csv('data/dailyNO2/daily_42602_2000.csv')\n",
    "NO2_2001 = pd.read_csv('data/dailyNO2/daily_42602_2001.csv')\n",
    "NO2_2002 = pd.read_csv('data/dailyNO2/daily_42602_2002.csv')\n",
    "NO2_2003 = pd.read_csv('data/dailyNO2/daily_42602_2003.csv')\n",
    "NO2_2004 = pd.read_csv('data/dailyNO2/daily_42602_2004.csv')\n",
    "NO2_2005 = pd.read_csv('data/dailyNO2/daily_42602_2005.csv')\n",
    "NO2_2006 = pd.read_csv('data/dailyNO2/daily_42602_2006.csv')\n",
    "NO2_2007 = pd.read_csv('data/dailyNO2/daily_42602_2007.csv')\n",
    "NO2_2008 = pd.read_csv('data/dailyNO2/daily_42602_2008.csv')\n",
    "NO2_2009 = pd.read_csv('data/dailyNO2/daily_42602_2009.csv')\n",
    "NO2_2010 = pd.read_csv('data/dailyNO2/daily_42602_2010.csv')\n",
    "NO2_2011 = pd.read_csv('data/dailyNO2/daily_42602_2011.csv')\n",
    "NO2_2012 = pd.read_csv('data/dailyNO2/daily_42602_2012.csv')\n",
    "NO2_2013 = pd.read_csv('data/dailyNO2/daily_42602_2013.csv')\n",
    "NO2_2014 = pd.read_csv('data/dailyNO2/daily_42602_2014.csv')\n",
    "NO2_2015 = pd.read_csv('data/dailyNO2/daily_42602_2015.csv')\n",
    "NO2_2016 = pd.read_csv('data/dailyNO2/daily_42602_2016.csv')\n",
    "NO2_2017 = pd.read_csv('data/dailyNO2/daily_42602_2017.csv')\n",
    "NO2_2018 = pd.read_csv('data/dailyNO2/daily_42602_2018.csv')\n",
    "NO2_2019 = pd.read_csv('data/dailyNO2/daily_42602_2019.csv')\n",
    "NO2_2020 = pd.read_csv('data/dailyNO2/daily_42602_2020.csv')\n",
    "NO2_2021 = pd.read_csv('data/dailyNO2/daily_42602_2021.csv')\n",
    "\n",
    "\n",
    "# Concatenate datasets\n",
    "NO2_all = [NO2_2000, NO2_2001, NO2_2002, NO2_2003, NO2_2004, NO2_2005, NO2_2006, NO2_2007, NO2_2008, NO2_2009, \n",
    "           NO2_2010, NO2_2011, NO2_2012, NO2_2013, NO2_2014, NO2_2015, NO2_2016, NO2_2017, NO2_2018, NO2_2019, \n",
    "           NO2_2020, NO2_2021]\n",
    "\n",
    "NO2 = pd.concat(NO2_all, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-size:1.2em;\"> <a id=\"Sulfur Dioxide\">Sulfur Dioxide</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T15:20:02.925101Z",
     "start_time": "2022-01-25T15:19:20.763231Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Sulfur Dioxide datasets\n",
    "SO2_2000 = pd.read_csv('data/dailySO2/daily_42401_2000.csv')\n",
    "SO2_2001 = pd.read_csv('data/dailySO2/daily_42401_2001.csv')\n",
    "SO2_2002 = pd.read_csv('data/dailySO2/daily_42401_2002.csv')\n",
    "SO2_2003 = pd.read_csv('data/dailySO2/daily_42401_2003.csv')\n",
    "SO2_2004 = pd.read_csv('data/dailySO2/daily_42401_2004.csv')\n",
    "SO2_2005 = pd.read_csv('data/dailySO2/daily_42401_2005.csv')\n",
    "SO2_2006 = pd.read_csv('data/dailySO2/daily_42401_2006.csv')\n",
    "SO2_2007 = pd.read_csv('data/dailySO2/daily_42401_2007.csv')\n",
    "SO2_2008 = pd.read_csv('data/dailySO2/daily_42401_2008.csv')\n",
    "SO2_2009 = pd.read_csv('data/dailySO2/daily_42401_2009.csv')\n",
    "SO2_2010 = pd.read_csv('data/dailySO2/daily_42401_2010.csv')\n",
    "SO2_2011 = pd.read_csv('data/dailySO2/daily_42401_2011.csv')\n",
    "SO2_2012 = pd.read_csv('data/dailySO2/daily_42401_2012.csv')\n",
    "SO2_2013 = pd.read_csv('data/dailySO2/daily_42401_2013.csv')\n",
    "SO2_2014 = pd.read_csv('data/dailySO2/daily_42401_2014.csv')\n",
    "SO2_2015 = pd.read_csv('data/dailySO2/daily_42401_2015.csv')\n",
    "SO2_2016 = pd.read_csv('data/dailySO2/daily_42401_2016.csv')\n",
    "SO2_2017 = pd.read_csv('data/dailySO2/daily_42401_2017.csv')\n",
    "SO2_2018 = pd.read_csv('data/dailySO2/daily_42401_2018.csv')\n",
    "SO2_2019 = pd.read_csv('data/dailySO2/daily_42401_2019.csv')\n",
    "SO2_2020 = pd.read_csv('data/dailySO2/daily_42401_2020.csv')\n",
    "SO2_2021 = pd.read_csv('data/dailySO2/daily_42401_2021.csv')\n",
    "\n",
    "\n",
    "# Concatenate datasets\n",
    "SO2_all = [SO2_2000, SO2_2001, SO2_2002, SO2_2003, SO2_2004, SO2_2005, SO2_2006, SO2_2007, SO2_2008, SO2_2009, \n",
    "           SO2_2010, SO2_2011, SO2_2012, SO2_2013, SO2_2014, SO2_2015, SO2_2016, SO2_2017, SO2_2018, SO2_2019, \n",
    "           SO2_2020, SO2_2021]\n",
    "\n",
    "SO2 = pd.concat(SO2_all, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-size:1.2em;\"> <a id=\"Creating Trim Pollutant Datasets\">Creating Trim Pollutant Datasets</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T15:20:03.010891Z",
     "start_time": "2022-01-25T15:20:02.932212Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to trim all four pollutant datasets\n",
    "\n",
    "def trim_dataset(df, pollutant):\n",
    "    \"\"\"\n",
    "    Trims down pollution datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "    pollutant: str, name of pollutant\n",
    "    \n",
    "    Returns:\n",
    "    ----------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # Drop columns that are not US states or DC\n",
    "    df.drop(df[(df['State Name'] == 'Country Of Mexico') | \n",
    "               (df['State Name'] == 'Virgin Islands') | \n",
    "               (df['State Name'] == 'Canada') | \n",
    "               (df['State Name'] == 'Puerto Rico')].index, inplace=True)\n",
    "    \n",
    "    # Drop pollutant standards that do not produce AQI values\n",
    "    if pollutant == 'CO':\n",
    "        df.drop(df[df['Pollutant Standard'] == ('CO 1-hour 1971')].index, inplace=True)\n",
    "    elif pollutant == 'SO2':\n",
    "        df.drop(df[df['Pollutant Standard'] == ('SO2 3-hour 1971')].index, inplace=True)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # Drop columns that are redundant or unnecessary\n",
    "    df.drop(['State Code', 'County Code', 'Site Num', 'Parameter Code', 'POC', 'Latitude', 'Longitude', \n",
    "             'Datum', 'Parameter Name', 'Sample Duration', 'Pollutant Standard', 'Units of Measure', \n",
    "             'Event Type', 'Observation Count', 'Observation Percent', 'Method Code', 'Method Name', \n",
    "             'Local Site Name', 'Address', 'CBSA Name', 'Date of Last Change'], axis=1, inplace=True)\n",
    "    \n",
    "    # Reorder columns for neatness\n",
    "    reordered = ['Date Local', 'State Name', 'County Name', 'City Name', \n",
    "                 'Arithmetic Mean', '1st Max Value', '1st Max Hour', 'AQI']\n",
    "    \n",
    "    df = df.reindex(columns=reordered)\n",
    "    \n",
    "    # Rename columns for neatness\n",
    "    df = df.rename(columns={'Date Local': 'Date', \n",
    "                            'State Name': 'State', \n",
    "                            'County Name': 'County', \n",
    "                            'City Name': 'City', \n",
    "                            'Arithmetic Mean': 'Mean', \n",
    "                            'AQI': '{} AQI'.format(pollutant)})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T15:21:09.981236Z",
     "start_time": "2022-01-25T15:20:03.014637Z"
    }
   },
   "outputs": [],
   "source": [
    "# Applying the function to datasets\n",
    "O3trim = trim_dataset(O3, 'O3')\n",
    "COtrim = trim_dataset(CO, 'CO')\n",
    "NO2trim = trim_dataset(NO2, 'NO2')\n",
    "SO2trim = trim_dataset(SO2, 'SO2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-size:1.2em;\"> <a id=\"Creating Time Series Datasets\">Creating Time Series Datasets</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T15:21:10.048839Z",
     "start_time": "2022-01-25T15:21:10.003289Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to make time series datasets\n",
    "\n",
    "def ts_dataset(df, pollutant):\n",
    "    \"\"\"\n",
    "    Creates time series datasets from trimmed pollutant datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "    pollutant: str, name of pollutant\n",
    "    \n",
    "    Returns:\n",
    "    ----------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # Drop mean, max value, and max hour columns\n",
    "    df.drop(['Mean', '1st Max Value', '1st Max Hour'], axis=1, inplace=True)\n",
    "    \n",
    "    # Set date as index\n",
    "    df.set_index(['Date'], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T15:21:12.808527Z",
     "start_time": "2022-01-25T15:21:10.068995Z"
    }
   },
   "outputs": [],
   "source": [
    "# Applying the function to create time series datasets\n",
    "O3ts = ts_dataset(O3trim, 'O3')\n",
    "COts = ts_dataset(COtrim, 'CO')\n",
    "NO2ts = ts_dataset(NO2trim, 'NO2')\n",
    "SO2ts = ts_dataset(SO2trim, 'SO2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T15:21:12.838722Z",
     "start_time": "2022-01-25T15:21:12.811881Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to make NYC time series datasets\n",
    "\n",
    "def nyc_ts_dataset(df, pollutant):\n",
    "    \"\"\"\n",
    "    Creates NYC time series datasets from time series datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "    pollutant: str, name of pollutant\n",
    "    \n",
    "    Returns:\n",
    "    ----------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # Keep rows for NYC then drop location columns\n",
    "    df = df[df['City']=='New York']\n",
    "    df.drop(['State', 'County', 'City'], axis=1, inplace=True)\n",
    "    \n",
    "    # Groupby date and take max AQI values if there are duplicates of the same date\n",
    "    df = df.groupby('Date').max()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T15:21:14.056370Z",
     "start_time": "2022-01-25T15:21:12.855182Z"
    }
   },
   "outputs": [],
   "source": [
    "# Applying the function to create NYC time series datasets\n",
    "nycO3 = nyc_ts_dataset(O3ts, 'O3')\n",
    "nycCO = nyc_ts_dataset(COts, 'CO')\n",
    "nycNO2 = nyc_ts_dataset(NO2ts, 'NO2')\n",
    "nycSO2 = nyc_ts_dataset(SO2ts, 'SO2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-size:1.2em;\"> <a id=\"Export\">Export</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T15:21:14.069521Z",
     "start_time": "2022-01-25T15:21:14.059665Z"
    }
   },
   "outputs": [],
   "source": [
    "# Export individual pollutant datasets\n",
    "# O3.to_csv('O3.csv', index=False)\n",
    "# CO.to_csv('CO.csv', index=False)\n",
    "# NO2.to_csv('NO2.csv', index=False)\n",
    "# SO2.to_csv('SO2.csv', index=False)\n",
    "\n",
    "# Export trim pollutant datasets\n",
    "# O3.to_csv('O3trim.csv', index=False)\n",
    "# CO.to_csv('COtrim.csv', index=False)\n",
    "# NO2.to_csv('NO2trim.csv', index=False)\n",
    "# SO2.to_csv('SO2trim.csv', index=False)\n",
    "\n",
    "# Export time series datasets\n",
    "# O3ts.to_csv('O3ts.csv')\n",
    "# COts.to_csv('COts.csv')\n",
    "# NO2ts.to_csv('NO2ts.csv')\n",
    "# SO2ts.to_csv('SO2ts.csv')\n",
    "\n",
    "# Export NYC time series datasets\n",
    "# nycO3.to_csv('nycO3.csv')\n",
    "# nycCO.to_csv('nycCO.csv')\n",
    "# nycNO2.to_csv('nycNO2.csv')\n",
    "# nycSO2.to_csv('nycSO2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-size:1.2em;\"> <a id=\"Sources\">Sources</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [EPA AirData Daily Summary Data](https://aqs.epa.gov/aqsweb/airdata/download_files.html#Daily)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
